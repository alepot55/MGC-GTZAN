{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e5e310",
   "metadata": {},
   "source": [
    "# Notebook 02: Analisi dei Risultati, Confronto e Inferenza\n",
    "\n",
    "**Scopo:** Questo notebook carica i modelli addestrati e i risultati salvati dal Notebook 01 per condurre un'analisi numerica e visiva approfondita. L'obiettivo √® confrontare le performance, interpretare i risultati e trarre conclusioni critiche.\n",
    "\n",
    "**Input:**\n",
    "- Modelli salvati da `../models/`\n",
    "- Dati di test da `../data/processed/`\n",
    "- Riepilogo del training da `../reports/training_summary.csv`\n",
    "- Artefatti di pre-processing da `../data/processed/` (`scaler.pkl`, `label_encoder.pkl`)\n",
    "\n",
    "**Output:**\n",
    "- Grafici comparativi (curve di apprendimento, performance su test set).\n",
    "- Matrici di confusione dettagliate.\n",
    "- Analisi degli errori per genere.\n",
    "- Conclusioni finali basate sui dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca2d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 00:50:49.371137: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-14 00:50:49.379505: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-14 00:50:49.445554: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-14 00:50:49.523212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752447049.595914   18471 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752447049.616545   18471 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752447049.753948   18471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752447049.754000   18471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752447049.754003   18471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752447049.754006   18471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-14 00:50:49.772287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå ERRORE: File di riepilogo '../reports/training_summary.csv' non trovato. Eseguire prima il notebook '01_Model_Training_and_Evaluation.ipynb'.\n",
      "‚úÖ Dati di test e artefatti caricati.\n",
      "   - Shape X_test: (1000, 128, 256, 1)\n",
      "\n",
      "‚úÖ Ambiente pronto per l'analisi.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 1: SETUP E CARICAMENTO DEI RISULTATI\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Configurazione Globale ---\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "MODELS_PATH = '../models/'\n",
    "REPORTS_PATH = '../reports/'\n",
    "\n",
    "# 1. Caricamento del Riepilogo del Training\n",
    "summary_path = os.path.join(REPORTS_PATH, 'training_summary.csv')\n",
    "if not os.path.exists(summary_path):\n",
    "    print(f\"‚ùå ERRORE: File di riepilogo '{summary_path}' non trovato. Eseguire prima il notebook '01_Model_Training_and_Evaluation.ipynb'.\")\n",
    "else:\n",
    "    results_df = pd.read_csv(summary_path)\n",
    "    print(\"‚úÖ Riepilogo del training caricato con successo.\")\n",
    "\n",
    "# 2. Caricamento dei Dati di Test e degli Artefatti\n",
    "try:\n",
    "    X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "    with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "    print(\"‚úÖ Dati di test e artefatti caricati.\")\n",
    "    print(f\"   - Shape X_test: {X_test.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERRORE: File di dati di test non trovati. Eseguire prima il notebook '00_Setup_and_Data_Preparation.ipynb'.\")\n",
    "    \n",
    "# 3. Visualizzazione Settings\n",
    "plt.style.use('seaborn-v0_8-talk')\n",
    "sns.set_palette(\"muted\")\n",
    "print(\"\\n‚úÖ Ambiente pronto per l'analisi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38448a9",
   "metadata": {},
   "source": [
    "## 1. Analisi delle Performance Complessive\n",
    "\n",
    "In questa sezione, visualizziamo e confrontiamo le performance finali di tutte le combinazioni modello-ottimizzatore sul **Test Set**. Questo ci fornisce una visione d'insieme su quale approccio ha funzionato meglio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d44c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è 'results_df' non trovato. Eseguire la cella precedente.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 2: GRAFICO RIASSUNTIVO DELLE PERFORMANCE\n",
    "# ===================================================================\n",
    "\n",
    "if 'results_df' in locals():\n",
    "    # Ordiniamo i risultati per la migliore accuracy per una visualizzazione pi√π chiara\n",
    "    results_df = results_df.sort_values(by='Test_Accuracy', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    barplot = sns.barplot(\n",
    "        data=results_df, \n",
    "        x='Test_Accuracy', \n",
    "        y='Experiment', # 'Experiment' √® il nome della colonna nel nuovo df\n",
    "        hue='Model', \n",
    "        dodge=False,\n",
    "        palette={'UNet_Lite': 'skyblue', 'SimpleCNN': 'salmon'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Confronto Accuratezza Finale su Test Set', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Accuracy', fontsize=14)\n",
    "    plt.ylabel('Esperimento (Modello + Ottimizzatore)', fontsize=14)\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Aggiungi etichette numeriche sulle barre\n",
    "    for i in barplot.containers:\n",
    "        barplot.bar_label(i, fmt='%.4f', fontsize=12, padding=5)\n",
    "        \n",
    "    plt.legend(title='Architettura', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n--- Riepilogo Tabellare ---\")\n",
    "    print(results_df[['Experiment', 'Test_Accuracy', 'Test_Loss', 'Best_Val_Accuracy']].round(4))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'results_df' non trovato. Eseguire la cella precedente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35c864",
   "metadata": {},
   "source": [
    "## 2. Analisi Approfondita del Miglior Modello\n",
    "\n",
    "Ora ci concentriamo sul modello che ha ottenuto la migliore performance sul test set. Analizzeremo in dettaglio i suoi errori attraverso la **matrice di confusione** e il **classification report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e892f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è 'results_df' non trovato. Eseguire la cella precedente.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 3: ANALISI DETTAGLIATA DEL MIGLIOR MODELLO\n",
    "# ===================================================================\n",
    "\n",
    "if 'results_df' in locals():\n",
    "    # 1. Identificare il miglior esperimento\n",
    "    best_experiment = results_df.loc[results_df['Test_Accuracy'].idxmax()]\n",
    "    best_model_name = best_experiment['Experiment']\n",
    "    model_path = os.path.join(MODELS_PATH, f\"{best_model_name}.keras\")\n",
    "    print(f\"üèÜ Miglior esperimento identificato: '{best_model_name}'\")\n",
    "    print(f\"   - Accuratezza su Test Set: {best_experiment['Test_Accuracy']:.4f}\")\n",
    "\n",
    "    # 2. Caricare il miglior modello salvato\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"üîÑ Caricamento del modello da: {model_path}\")\n",
    "        # Creiamo un custom_objects per PReLU se usato\n",
    "        custom_objects = {'PReLU': layers.PReLU} \n",
    "        best_model = models.load_model(model_path, custom_objects=custom_objects)\n",
    "        \n",
    "        # 3. Generare predizioni e report\n",
    "        print(\"üîç Generazione delle predizioni sul test set...\")\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "        \n",
    "        class_names = label_encoder.classes_\n",
    "        \n",
    "        print(\"\\n--- Classification Report Dettagliato ---\")\n",
    "        print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
    "        \n",
    "        # 4. Visualizzare la Matrice di Confusione\n",
    "        cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f'Matrice di Confusione per {best_model_name}', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Genere Predetto', fontsize=12)\n",
    "        plt.ylabel('Genere Reale', fontsize=12)\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå ERRORE: File del modello '{model_path}' non trovato.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'results_df' non trovato. Eseguire la cella precedente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c92132",
   "metadata": {},
   "source": [
    "## 3. Analisi Numerica degli Ottimizzatori e Conclusioni Finali\n",
    "\n",
    "Infine, analizziamo l'impatto dei diversi ottimizzatori e traiamo le conclusioni finali del nostro progetto.\n",
    "\n",
    "### 3.1 Confronto Ottimizzatori\n",
    "Analizziamo le performance medie per ogni ottimizzatore, considerando entrambe le architetture.\n",
    "\n",
    "### 3.2 Conclusioni\n",
    "Sintetizziamo i punti chiave emersi:\n",
    "- Confronto tra le performance realistiche e quelle del paper.\n",
    "- Valutazione del trade-off complessit√†-accuratezza tra U-Net e CNN semplice.\n",
    "- Discussione sul ruolo della regolarizzazione e della data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcacc5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Eseguire le celle precedenti per generare i risultati.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 4: ANALISI FINALE E CONCLUSIONI\n",
    "# ===================================================================\n",
    "\n",
    "if 'results_df' in locals():\n",
    "    # 1. Analisi per Ottimizzatore\n",
    "    optimizer_comparison = results_df.groupby('Optimizer')['Test_Accuracy'].agg(['mean', 'std', 'max']).sort_values(by='mean', ascending=False)\n",
    "    print(\"--- Analisi Performance per Ottimizzatore (Media su tutti i modelli) ---\")\n",
    "    print(optimizer_comparison.round(4))\n",
    "    \n",
    "    # 2. Analisi per Architettura\n",
    "    model_comparison = results_df.groupby('Model')['Test_Accuracy'].agg(['mean', 'std', 'max']).sort_values(by='mean', ascending=False)\n",
    "    print(\"\\n--- Analisi Performance per Architettura (Media su tutti gli ottimizzatori) ---\")\n",
    "    print(model_comparison.round(4))\n",
    "    \n",
    "    # 3. Conclusioni Scritte\n",
    "    best_overall = results_df.loc[results_df['Test_Accuracy'].idxmax()]\n",
    "    \n",
    "    print(\"\\n=========================================================\")\n",
    "    print(\"CONCLUSIONS FINALI DEL PROGETTO\")\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"1.  **Performance Realistica:** Il nostro miglior modello ({best_overall['Experiment']}) ha raggiunto un'accuratezza del \"\n",
    "          f\"**{best_overall['Test_Accuracy']:.2%}** sul test set. Questo risultato √® in linea con lo stato dell'arte per GTZAN \"\n",
    "          f\"usando una metodologia rigorosa, e smentisce il 99.41% dichiarato nel paper di riferimento, probabilmente viziato da data leakage.\")\n",
    "    \n",
    "    print(f\"\\n2.  **Trade-off Architettura:** L'architettura '{model_comparison.index[0]}' ha mostrato in media le migliori performance \"\n",
    "          f\"({model_comparison['mean'].iloc[0]:.2%}), ma la differenza con la '{model_comparison.index[1]}' \"\n",
    "          f\"({model_comparison['mean'].iloc[1]:.2%}) potrebbe non giustificare l'aumento di complessit√† e tempo di training. \"\n",
    "          \"Questo suggerisce di iniziare sempre con un baseline pi√π semplice.\")\n",
    "          \n",
    "    print(f\"\\n3.  **Impatto dell'Ottimizzatore:** L'ottimizzatore '{optimizer_comparison.index[0]}' ha fornito in media i risultati pi√π alti \"\n",
    "          f\"({optimizer_comparison['mean'].iloc[0]:.2%}), dimostrando un eccellente equilibrio tra velocit√† di convergenza e capacit√† \"\n",
    "          \"di generalizzazione in questo dominio, specialmente quando combinato con una forte regolarizzazione.\")\n",
    "\n",
    "    print(f\"\\n4.  **Lezione Chiave:** La rigorosa metodologia di valutazione (split corretto, data augmentation, confronto di iperparametri) \"\n",
    "          \"√® pi√π importante della scelta di un'architettura eccessivamente complessa. Il nostro progetto ha prodotto risultati affidabili e \"\n",
    "          \"interpretabili, fornendo una base solida per future ricerche.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Eseguire le celle precedenti per generare i risultati.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
