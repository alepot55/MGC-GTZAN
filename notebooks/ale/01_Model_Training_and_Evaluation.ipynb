{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec7b1a4",
   "metadata": {},
   "source": [
    "# Notebook 01: Addestramento e Valutazione dei Modelli\n",
    "\n",
    "**Scopo:** Questo notebook carica i dati pre-processati dal Notebook 00, definisce le architetture delle reti neurali, orchestra un ciclo di esperimenti per addestrare e valutare diverse combinazioni di modelli e ottimizzatori, e salva gli artefatti migliori per l'analisi successiva.\n",
    "\n",
    "**Input:**\n",
    "- Dati pre-processati da `../data/processed/` (`X_train.npy`, `y_train.npy`, etc.)\n",
    "\n",
    "**Output (salvati in `../models/` e `../reports/`):**\n",
    "- I modelli migliori per ogni esperimento (es. `UNet_Lite_Adam.keras`).\n",
    "- Un file di riepilogo con le metriche di performance (es. `training_summary.csv`).\n",
    "- (Opzionale) Le storie di training salvate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe0892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU(s) Trovata/e: ['NVIDIA GeForce RTX 4070']\n",
      "✅ Politica di Mixed Precision impostata su: mixed_float16\n",
      "\n",
      "🔄 Caricamento dei dati pre-processati...\n",
      "\n",
      "✅ Dati caricati con successo.\n",
      "   - Shape X_train: (5990, 128, 128, 1) | Shape y_train_cat: (5990, 10)\n",
      "   - Numero di classi: 10\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 1: SETUP, IMPORTS E CARICAMENTO DATI\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import layers, models, optimizers, callbacks, regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# --- Configurazione Globale ---\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "MODELS_PATH = '../models/ale/'\n",
    "REPORTS_PATH = '../reports/'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "\n",
    "# 1. GPU e Mixed Precision\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ GPU(s) Trovata/e: {[tf.config.experimental.get_device_details(g)['device_name'] for g in gpus]}\")\n",
    "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "        keras.mixed_precision.set_global_policy(policy)\n",
    "        print(f\"✅ Politica di Mixed Precision impostata su: {keras.mixed_precision.global_policy().name}\")\n",
    "    except RuntimeError as e: print(f\"⚠️ Errore durante l'inizializzazione della GPU: {e}\")\n",
    "else: print(\"❌ NESSUNA GPU TROVATA. L'allenamento sarà su CPU.\")\n",
    "\n",
    "# 2. Caricamento Dati Pre-processati\n",
    "print(\"\\n🔄 Caricamento dei dati pre-processati...\")\n",
    "try:\n",
    "    X_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_train.npy'))\n",
    "    y_train = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_train.npy'))\n",
    "    X_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_val.npy'))\n",
    "    y_val = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_val.npy'))\n",
    "    X_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(PROCESSED_DATA_PATH, 'y_test.npy'))\n",
    "    \n",
    "    with open(os.path.join(PROCESSED_DATA_PATH, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "\n",
    "    # Conversione in formato categorico\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    print(\"\\n✅ Dati caricati con successo.\")\n",
    "    print(f\"   - Shape X_train: {X_train.shape} | Shape y_train_cat: {y_train_cat.shape}\")\n",
    "    print(f\"   - Numero di classi: {num_classes}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ ERRORE: File di dati non trovati. Eseguire prima il notebook '00_Setup_and_Data_Preparation.ipynb'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56958c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ModelFactory pronta per il torneo con i 3 migliori candidati.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 2: MODELFACTORY PER IL \"GRAND TOURNAMENT\"\n",
    "# ===================================================================\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "class ModelFactory:\n",
    "    \"\"\"\n",
    "    Contiene le factory per i nostri tre migliori candidati.\n",
    "    Ogni modello rappresenta un diverso compromesso tra semplicità e potenza.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _se_block(input_tensor, ratio=16):\n",
    "        channels = input_tensor.shape[-1]\n",
    "        se = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        se = layers.Reshape((1, 1, channels))(se)\n",
    "        se = layers.Dense(channels // ratio, activation='relu')(se)\n",
    "        se = layers.Dense(channels, activation='sigmoid')(se)\n",
    "        return layers.Multiply()([input_tensor, se])\n",
    "\n",
    "    # --- Candidato 1: Il Campione Stabile ---\n",
    "    @staticmethod\n",
    "    def build_se_audio_cnn(input_shape, num_classes):\n",
    "        \"\"\"Architettura VGG-style potenziata con SE. Semplice, veloce, robusta.\"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # Blocco 1\n",
    "        x = layers.Conv2D(32, (3, 3), padding='same', use_bias=False)(inputs)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(32, (3, 3), padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = ModelFactory._se_block(x)\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "        # Blocco 2\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = ModelFactory._se_block(x)\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "        # Testa\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='SE_AudioCNN')\n",
    "\n",
    "    # --- Candidato 2: L'Equilibrio di Potenza ---\n",
    "    @staticmethod\n",
    "    def _res_se_block(input_tensor, filters, stride=1):\n",
    "        shortcut = input_tensor\n",
    "        x = layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False)(input_tensor)\n",
    "        x = layers.BatchNormalization()(x); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        x = layers.Conv2D(filters, 3, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = ModelFactory._se_block(x)\n",
    "        if stride > 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "        x = layers.Add()([shortcut, x]); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def build_res_se_audio_cnn(input_shape, num_classes):\n",
    "        \"\"\"Architettura ResNet-style con SE e PReLU. Potente e stabile.\"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = layers.Conv2D(32, 3, strides=1, padding='same', use_bias=False)(inputs)\n",
    "        x = layers.BatchNormalization()(x); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        x = ModelFactory._res_se_block(x, 64, stride=2)\n",
    "        x = ModelFactory._res_se_block(x, 128, stride=2)\n",
    "        x = ModelFactory._res_se_block(x, 256, stride=2)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='ResSE_AudioCNN')\n",
    "\n",
    "    # --- Candidato 3: La Punta di Diamante ---\n",
    "    @staticmethod\n",
    "    def _resnext_se_block(input_tensor, filters, stride=1, cardinality=8):\n",
    "        shortcut = input_tensor\n",
    "        if stride > 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "        x = layers.Conv2D(filters // 2, 1, use_bias=False)(input_tensor)\n",
    "        x = layers.BatchNormalization()(x); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        group_filters = (filters // 2) // cardinality\n",
    "        groups = [layers.Conv2D(group_filters, 3, strides=stride, padding='same', use_bias=False)(x) for _ in range(cardinality)]\n",
    "        x = layers.Concatenate()(groups)\n",
    "        x = layers.BatchNormalization()(x); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        x = layers.Conv2D(filters, 1, use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x); x = ModelFactory._se_block(x)\n",
    "        x = layers.Add()([shortcut, x]); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnext_se_audio_cnn(input_shape, num_classes):\n",
    "        \"\"\"Architettura ResNeXt-style. La nostra opzione più potente.\"\"\"\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = layers.Conv2D(64, 3, strides=1, padding='same', use_bias=False)(inputs)\n",
    "        x = layers.BatchNormalization()(x); x = layers.PReLU(shared_axes=[1, 2])(x)\n",
    "        x = ModelFactory._resnext_se_block(x, 128, stride=2)\n",
    "        x = ModelFactory._resnext_se_block(x, 256, stride=2)\n",
    "        x = ModelFactory._resnext_se_block(x, 512, stride=2)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        return models.Model(inputs=inputs, outputs=outputs, name='ResNeXt_SE_AudioCNN')\n",
    "\n",
    "print(\"✅ ModelFactory pronta per il torneo con i 3 migliori candidati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ARCHITETTURA IN TEST: 'SE_AudioCNN'\n",
      "================================================================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 14:55:46.649906: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_270', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 21s - 220ms/step - accuracy: 0.2997 - loss: 1.9117 - val_accuracy: 0.2035 - val_loss: 2.1381 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.4083 - loss: 1.5999 - val_accuracy: 0.2335 - val_loss: 2.0751 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.4584 - loss: 1.4955 - val_accuracy: 0.2915 - val_loss: 1.8429 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.5015 - loss: 1.3805 - val_accuracy: 0.3105 - val_loss: 1.9694 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.5611 - loss: 1.2618 - val_accuracy: 0.4755 - val_loss: 1.5652 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.5922 - loss: 1.1579 - val_accuracy: 0.3295 - val_loss: 2.1600 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.6105 - loss: 1.1114 - val_accuracy: 0.5340 - val_loss: 1.3237 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.6326 - loss: 1.0570 - val_accuracy: 0.6230 - val_loss: 1.1368 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.6416 - loss: 1.0211 - val_accuracy: 0.5715 - val_loss: 1.2146 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.6554 - loss: 0.9940 - val_accuracy: 0.4440 - val_loss: 1.7136 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.6831 - loss: 0.9315 - val_accuracy: 0.4620 - val_loss: 1.8893 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.6806 - loss: 0.9242 - val_accuracy: 0.5335 - val_loss: 1.4443 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.6945 - loss: 0.8993 - val_accuracy: 0.4790 - val_loss: 1.9917 - learning_rate: 1.0000e-03\n",
      "Epoch 14/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7164 - loss: 0.8233 - val_accuracy: 0.7080 - val_loss: 0.9218 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7361 - loss: 0.7830 - val_accuracy: 0.6900 - val_loss: 0.9697 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7382 - loss: 0.7819 - val_accuracy: 0.6550 - val_loss: 1.0247 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7401 - loss: 0.7713 - val_accuracy: 0.5870 - val_loss: 1.2821 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7391 - loss: 0.7633 - val_accuracy: 0.6900 - val_loss: 0.9906 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7442 - loss: 0.7595 - val_accuracy: 0.6405 - val_loss: 1.0995 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7467 - loss: 0.7459 - val_accuracy: 0.7050 - val_loss: 0.9221 - learning_rate: 4.0000e-05\n",
      "Epoch 21/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7501 - loss: 0.7355 - val_accuracy: 0.7195 - val_loss: 0.9087 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7556 - loss: 0.7229 - val_accuracy: 0.7100 - val_loss: 0.9105 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7464 - loss: 0.7315 - val_accuracy: 0.7175 - val_loss: 0.8946 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7516 - loss: 0.7203 - val_accuracy: 0.7100 - val_loss: 0.9172 - learning_rate: 4.0000e-05\n",
      "Epoch 25/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7559 - loss: 0.7259 - val_accuracy: 0.7180 - val_loss: 0.9075 - learning_rate: 4.0000e-05\n",
      "Epoch 26/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7464 - loss: 0.7389 - val_accuracy: 0.7100 - val_loss: 0.9191 - learning_rate: 4.0000e-05\n",
      "Epoch 27/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7556 - loss: 0.7293 - val_accuracy: 0.7060 - val_loss: 0.9154 - learning_rate: 4.0000e-05\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7571 - loss: 0.7163 - val_accuracy: 0.7160 - val_loss: 0.9179 - learning_rate: 4.0000e-05\n",
      "Epoch 29/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7671 - loss: 0.7115 - val_accuracy: 0.7185 - val_loss: 0.8979 - learning_rate: 8.0000e-06\n",
      "Epoch 30/50\n",
      "94/94 - 3s - 34ms/step - accuracy: 0.7629 - loss: 0.7145 - val_accuracy: 0.7225 - val_loss: 0.8950 - learning_rate: 8.0000e-06\n",
      "Epoch 31/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7621 - loss: 0.7205 - val_accuracy: 0.7205 - val_loss: 0.8922 - learning_rate: 8.0000e-06\n",
      "Epoch 32/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7648 - loss: 0.7171 - val_accuracy: 0.7210 - val_loss: 0.8933 - learning_rate: 8.0000e-06\n",
      "Epoch 33/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7679 - loss: 0.7124 - val_accuracy: 0.7185 - val_loss: 0.8953 - learning_rate: 8.0000e-06\n",
      "Epoch 34/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7634 - loss: 0.7120 - val_accuracy: 0.7215 - val_loss: 0.8890 - learning_rate: 8.0000e-06\n",
      "Epoch 35/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7608 - loss: 0.7128 - val_accuracy: 0.7185 - val_loss: 0.8953 - learning_rate: 8.0000e-06\n",
      "Epoch 36/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7583 - loss: 0.7159 - val_accuracy: 0.7190 - val_loss: 0.8923 - learning_rate: 8.0000e-06\n",
      "Epoch 37/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7631 - loss: 0.7058 - val_accuracy: 0.7200 - val_loss: 0.8869 - learning_rate: 8.0000e-06\n",
      "Epoch 38/50\n",
      "94/94 - 3s - 34ms/step - accuracy: 0.7566 - loss: 0.7205 - val_accuracy: 0.7230 - val_loss: 0.8953 - learning_rate: 8.0000e-06\n",
      "Epoch 39/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7564 - loss: 0.7125 - val_accuracy: 0.7230 - val_loss: 0.8915 - learning_rate: 8.0000e-06\n",
      "Epoch 40/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7603 - loss: 0.7105 - val_accuracy: 0.7205 - val_loss: 0.8931 - learning_rate: 8.0000e-06\n",
      "Epoch 41/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7659 - loss: 0.7110 - val_accuracy: 0.7165 - val_loss: 0.8975 - learning_rate: 8.0000e-06\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7648 - loss: 0.7048 - val_accuracy: 0.7190 - val_loss: 0.8979 - learning_rate: 8.0000e-06\n",
      "Epoch 43/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7579 - loss: 0.7166 - val_accuracy: 0.7235 - val_loss: 0.8939 - learning_rate: 1.6000e-06\n",
      "Epoch 44/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7634 - loss: 0.7088 - val_accuracy: 0.7205 - val_loss: 0.8918 - learning_rate: 1.6000e-06\n",
      "Epoch 45/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7656 - loss: 0.7068 - val_accuracy: 0.7205 - val_loss: 0.8926 - learning_rate: 1.6000e-06\n",
      "Epoch 46/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7591 - loss: 0.7122 - val_accuracy: 0.7215 - val_loss: 0.8924 - learning_rate: 1.6000e-06\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7599 - loss: 0.7042 - val_accuracy: 0.7220 - val_loss: 0.8922 - learning_rate: 1.6000e-06\n",
      "Epoch 48/50\n",
      "94/94 - 3s - 32ms/step - accuracy: 0.7644 - loss: 0.7028 - val_accuracy: 0.7215 - val_loss: 0.8921 - learning_rate: 3.2000e-07\n",
      "Epoch 49/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7676 - loss: 0.7099 - val_accuracy: 0.7225 - val_loss: 0.8918 - learning_rate: 3.2000e-07\n",
      "Epoch 50/50\n",
      "94/94 - 3s - 33ms/step - accuracy: 0.7593 - loss: 0.7027 - val_accuracy: 0.7215 - val_loss: 0.8924 - learning_rate: 3.2000e-07\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "\n",
      "================================================================================\n",
      "ARCHITETTURA IN TEST: 'ResSE_AudioCNN'\n",
      "================================================================================\n",
      "Epoch 1/50\n",
      "94/94 - 22s - 235ms/step - accuracy: 0.4013 - loss: 1.6534 - val_accuracy: 0.1565 - val_loss: 3.0700 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "94/94 - 4s - 41ms/step - accuracy: 0.5669 - loss: 1.2116 - val_accuracy: 0.1985 - val_loss: 4.1048 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.6598 - loss: 1.0005 - val_accuracy: 0.1895 - val_loss: 5.3232 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "94/94 - 4s - 42ms/step - accuracy: 0.7140 - loss: 0.8371 - val_accuracy: 0.4710 - val_loss: 1.9664 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "94/94 - 4s - 43ms/step - accuracy: 0.7568 - loss: 0.7164 - val_accuracy: 0.5100 - val_loss: 2.1649 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.8007 - loss: 0.5883 - val_accuracy: 0.5035 - val_loss: 2.0556 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "94/94 - 4s - 42ms/step - accuracy: 0.8352 - loss: 0.4852 - val_accuracy: 0.6600 - val_loss: 1.1848 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.8609 - loss: 0.4085 - val_accuracy: 0.6195 - val_loss: 1.6563 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.8830 - loss: 0.3532 - val_accuracy: 0.6335 - val_loss: 1.2655 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9072 - loss: 0.2713 - val_accuracy: 0.4295 - val_loss: 3.6059 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9294 - loss: 0.2183 - val_accuracy: 0.5385 - val_loss: 2.0067 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.9444 - loss: 0.1706 - val_accuracy: 0.3815 - val_loss: 5.0702 - learning_rate: 1.0000e-03\n",
      "Epoch 13/50\n",
      "94/94 - 4s - 43ms/step - accuracy: 0.9775 - loss: 0.0957 - val_accuracy: 0.7235 - val_loss: 1.0286 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9838 - loss: 0.0723 - val_accuracy: 0.7185 - val_loss: 1.0341 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "94/94 - 4s - 42ms/step - accuracy: 0.9856 - loss: 0.0631 - val_accuracy: 0.7655 - val_loss: 0.9649 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "94/94 - 4s - 42ms/step - accuracy: 0.9898 - loss: 0.0515 - val_accuracy: 0.7780 - val_loss: 0.8394 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9896 - loss: 0.0495 - val_accuracy: 0.7420 - val_loss: 0.9930 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.9920 - loss: 0.0431 - val_accuracy: 0.7645 - val_loss: 0.9761 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9908 - loss: 0.0434 - val_accuracy: 0.7640 - val_loss: 1.0143 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.9933 - loss: 0.0370 - val_accuracy: 0.7465 - val_loss: 1.1642 - learning_rate: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9947 - loss: 0.0326 - val_accuracy: 0.7690 - val_loss: 0.9292 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "94/94 - 4s - 44ms/step - accuracy: 0.9947 - loss: 0.0290 - val_accuracy: 0.7850 - val_loss: 0.8333 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9960 - loss: 0.0294 - val_accuracy: 0.7850 - val_loss: 0.8331 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.9952 - loss: 0.0276 - val_accuracy: 0.7815 - val_loss: 0.8744 - learning_rate: 4.0000e-05\n",
      "Epoch 25/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9960 - loss: 0.0254 - val_accuracy: 0.7800 - val_loss: 0.8844 - learning_rate: 4.0000e-05\n",
      "Epoch 26/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9963 - loss: 0.0251 - val_accuracy: 0.7830 - val_loss: 0.8547 - learning_rate: 4.0000e-05\n",
      "Epoch 27/50\n",
      "94/94 - 4s - 42ms/step - accuracy: 0.9972 - loss: 0.0246 - val_accuracy: 0.7930 - val_loss: 0.8394 - learning_rate: 4.0000e-05\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9960 - loss: 0.0252 - val_accuracy: 0.7845 - val_loss: 0.8736 - learning_rate: 4.0000e-05\n",
      "Epoch 29/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9980 - loss: 0.0205 - val_accuracy: 0.7910 - val_loss: 0.8496 - learning_rate: 8.0000e-06\n",
      "Epoch 30/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9958 - loss: 0.0257 - val_accuracy: 0.7880 - val_loss: 0.8495 - learning_rate: 8.0000e-06\n",
      "Epoch 31/50\n",
      "94/94 - 4s - 39ms/step - accuracy: 0.9950 - loss: 0.0252 - val_accuracy: 0.7870 - val_loss: 0.8480 - learning_rate: 8.0000e-06\n",
      "Epoch 32/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9970 - loss: 0.0235 - val_accuracy: 0.7880 - val_loss: 0.8473 - learning_rate: 8.0000e-06\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9975 - loss: 0.0222 - val_accuracy: 0.7900 - val_loss: 0.8442 - learning_rate: 8.0000e-06\n",
      "Epoch 34/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9977 - loss: 0.0226 - val_accuracy: 0.7900 - val_loss: 0.8452 - learning_rate: 1.6000e-06\n",
      "Epoch 35/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9972 - loss: 0.0225 - val_accuracy: 0.7890 - val_loss: 0.8456 - learning_rate: 1.6000e-06\n",
      "Epoch 36/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9973 - loss: 0.0221 - val_accuracy: 0.7880 - val_loss: 0.8454 - learning_rate: 1.6000e-06\n",
      "Epoch 37/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9975 - loss: 0.0231 - val_accuracy: 0.7885 - val_loss: 0.8477 - learning_rate: 1.6000e-06\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9963 - loss: 0.0221 - val_accuracy: 0.7890 - val_loss: 0.8436 - learning_rate: 1.6000e-06\n",
      "Epoch 39/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9963 - loss: 0.0240 - val_accuracy: 0.7890 - val_loss: 0.8432 - learning_rate: 3.2000e-07\n",
      "Epoch 40/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9977 - loss: 0.0216 - val_accuracy: 0.7905 - val_loss: 0.8451 - learning_rate: 3.2000e-07\n",
      "Epoch 41/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9975 - loss: 0.0223 - val_accuracy: 0.7895 - val_loss: 0.8471 - learning_rate: 3.2000e-07\n",
      "Epoch 42/50\n",
      "94/94 - 4s - 40ms/step - accuracy: 0.9957 - loss: 0.0242 - val_accuracy: 0.7895 - val_loss: 0.8463 - learning_rate: 3.2000e-07\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "================================================================================\n",
      "ARCHITETTURA IN TEST: 'ResNeXt_SE_AudioCNN'\n",
      "================================================================================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 15:01:28.759848: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 448 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "2025-07-25 15:01:55.999911: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 476 bytes spill stores, 476 bytes spill loads\n",
      "\n",
      "2025-07-25 15:01:56.045720: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-07-25 15:02:09.464083: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-07-25 15:02:09.646683: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_630', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 59s - 629ms/step - accuracy: 0.4297 - loss: 1.6043 - val_accuracy: 0.1595 - val_loss: 3.7259 - learning_rate: 1.0000e-03\n",
      "Epoch 2/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.5701 - loss: 1.1754 - val_accuracy: 0.0845 - val_loss: 6.3565 - learning_rate: 1.0000e-03\n",
      "Epoch 3/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.6616 - loss: 0.9843 - val_accuracy: 0.1485 - val_loss: 4.5496 - learning_rate: 1.0000e-03\n",
      "Epoch 4/50\n",
      "94/94 - 12s - 128ms/step - accuracy: 0.7002 - loss: 0.8541 - val_accuracy: 0.3485 - val_loss: 3.1679 - learning_rate: 1.0000e-03\n",
      "Epoch 5/50\n",
      "94/94 - 12s - 129ms/step - accuracy: 0.7536 - loss: 0.7137 - val_accuracy: 0.4140 - val_loss: 2.1374 - learning_rate: 1.0000e-03\n",
      "Epoch 6/50\n",
      "94/94 - 12s - 128ms/step - accuracy: 0.7888 - loss: 0.6080 - val_accuracy: 0.6730 - val_loss: 1.1723 - learning_rate: 1.0000e-03\n",
      "Epoch 7/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.8277 - loss: 0.5152 - val_accuracy: 0.4850 - val_loss: 2.9013 - learning_rate: 1.0000e-03\n",
      "Epoch 8/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.8496 - loss: 0.4380 - val_accuracy: 0.4245 - val_loss: 3.9116 - learning_rate: 1.0000e-03\n",
      "Epoch 9/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.8831 - loss: 0.3523 - val_accuracy: 0.5735 - val_loss: 2.1629 - learning_rate: 1.0000e-03\n",
      "Epoch 10/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9032 - loss: 0.2917 - val_accuracy: 0.6025 - val_loss: 1.6974 - learning_rate: 1.0000e-03\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9180 - loss: 0.2418 - val_accuracy: 0.4915 - val_loss: 2.6103 - learning_rate: 1.0000e-03\n",
      "Epoch 12/50\n",
      "94/94 - 12s - 128ms/step - accuracy: 0.9631 - loss: 0.1353 - val_accuracy: 0.7300 - val_loss: 0.8496 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "94/94 - 12s - 127ms/step - accuracy: 0.9733 - loss: 0.0986 - val_accuracy: 0.7655 - val_loss: 0.8037 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9803 - loss: 0.0822 - val_accuracy: 0.7355 - val_loss: 0.9585 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9863 - loss: 0.0646 - val_accuracy: 0.7250 - val_loss: 0.9505 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9876 - loss: 0.0603 - val_accuracy: 0.7235 - val_loss: 0.9932 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9883 - loss: 0.0544 - val_accuracy: 0.7510 - val_loss: 0.9196 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9905 - loss: 0.0499 - val_accuracy: 0.7585 - val_loss: 0.9443 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "94/94 - 12s - 127ms/step - accuracy: 0.9937 - loss: 0.0400 - val_accuracy: 0.7665 - val_loss: 0.8986 - learning_rate: 4.0000e-05\n",
      "Epoch 20/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9938 - loss: 0.0369 - val_accuracy: 0.7650 - val_loss: 0.9077 - learning_rate: 4.0000e-05\n",
      "Epoch 21/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9953 - loss: 0.0336 - val_accuracy: 0.7540 - val_loss: 0.9727 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9948 - loss: 0.0325 - val_accuracy: 0.7645 - val_loss: 0.9618 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9933 - loss: 0.0340 - val_accuracy: 0.7590 - val_loss: 0.9446 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9952 - loss: 0.0356 - val_accuracy: 0.7610 - val_loss: 0.9398 - learning_rate: 8.0000e-06\n",
      "Epoch 25/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9937 - loss: 0.0339 - val_accuracy: 0.7625 - val_loss: 0.9328 - learning_rate: 8.0000e-06\n",
      "Epoch 26/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9938 - loss: 0.0322 - val_accuracy: 0.7665 - val_loss: 0.9240 - learning_rate: 8.0000e-06\n",
      "Epoch 27/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9937 - loss: 0.0334 - val_accuracy: 0.7660 - val_loss: 0.9229 - learning_rate: 8.0000e-06\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9960 - loss: 0.0301 - val_accuracy: 0.7655 - val_loss: 0.9297 - learning_rate: 8.0000e-06\n",
      "Epoch 29/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9967 - loss: 0.0300 - val_accuracy: 0.7655 - val_loss: 0.9327 - learning_rate: 1.6000e-06\n",
      "Epoch 30/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9953 - loss: 0.0293 - val_accuracy: 0.7660 - val_loss: 0.9306 - learning_rate: 1.6000e-06\n",
      "Epoch 31/50\n",
      "94/94 - 12s - 127ms/step - accuracy: 0.9940 - loss: 0.0320 - val_accuracy: 0.7675 - val_loss: 0.9330 - learning_rate: 1.6000e-06\n",
      "Epoch 32/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9943 - loss: 0.0334 - val_accuracy: 0.7665 - val_loss: 0.9323 - learning_rate: 1.6000e-06\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9960 - loss: 0.0306 - val_accuracy: 0.7655 - val_loss: 0.9326 - learning_rate: 1.6000e-06\n",
      "Epoch 34/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9950 - loss: 0.0306 - val_accuracy: 0.7645 - val_loss: 0.9322 - learning_rate: 3.2000e-07\n",
      "Epoch 35/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9948 - loss: 0.0336 - val_accuracy: 0.7645 - val_loss: 0.9315 - learning_rate: 3.2000e-07\n",
      "Epoch 36/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9943 - loss: 0.0331 - val_accuracy: 0.7645 - val_loss: 0.9306 - learning_rate: 3.2000e-07\n",
      "Epoch 37/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9953 - loss: 0.0323 - val_accuracy: 0.7630 - val_loss: 0.9321 - learning_rate: 3.2000e-07\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9933 - loss: 0.0340 - val_accuracy: 0.7650 - val_loss: 0.9306 - learning_rate: 3.2000e-07\n",
      "Epoch 39/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9937 - loss: 0.0340 - val_accuracy: 0.7625 - val_loss: 0.9317 - learning_rate: 6.4000e-08\n",
      "Epoch 40/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9940 - loss: 0.0342 - val_accuracy: 0.7650 - val_loss: 0.9307 - learning_rate: 6.4000e-08\n",
      "Epoch 41/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9932 - loss: 0.0335 - val_accuracy: 0.7655 - val_loss: 0.9312 - learning_rate: 6.4000e-08\n",
      "Epoch 42/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9940 - loss: 0.0327 - val_accuracy: 0.7645 - val_loss: 0.9307 - learning_rate: 6.4000e-08\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9967 - loss: 0.0296 - val_accuracy: 0.7655 - val_loss: 0.9310 - learning_rate: 6.4000e-08\n",
      "Epoch 44/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9948 - loss: 0.0328 - val_accuracy: 0.7670 - val_loss: 0.9327 - learning_rate: 1.2800e-08\n",
      "Epoch 45/50\n",
      "94/94 - 12s - 125ms/step - accuracy: 0.9942 - loss: 0.0334 - val_accuracy: 0.7670 - val_loss: 0.9337 - learning_rate: 1.2800e-08\n",
      "Epoch 46/50\n",
      "94/94 - 12s - 126ms/step - accuracy: 0.9942 - loss: 0.0339 - val_accuracy: 0.7665 - val_loss: 0.9311 - learning_rate: 1.2800e-08\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "\n",
      "🎉 TORNEO COMPLETATO 🎉\n",
      "\n",
      "Classifica Finale:\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/pandas/compat/_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 TORNEO COMPLETATO 🎉\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassifica Finale:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBest_Val_Accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/pandas/core/frame.py:2988\u001b[39m, in \u001b[36mDataFrame.to_markdown\u001b[39m\u001b[34m(self, buf, mode, index, storage_options, **kwargs)\u001b[39m\n\u001b[32m   2986\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mtablefmt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2987\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mshowindex\u001b[39m\u001b[33m\"\u001b[39m, index)\n\u001b[32m-> \u001b[39m\u001b[32m2988\u001b[39m tabulate = \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtabulate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2989\u001b[39m result = tabulate.tabulate(\u001b[38;5;28mself\u001b[39m, **kwargs)\n\u001b[32m   2990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/naml_project/venv/lib/python3.12/site-packages/pandas/compat/_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELLA 3: FRAMEWORK DI TRAINING PER IL \"GRAND TOURNAMENT\"\n",
    "# ===================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "\n",
    "# Funzione SpecAugment (invariata)\n",
    "@tf.function\n",
    "def spec_augment_tf(spectrogram, label):\n",
    "    aug_spec = tf.identity(spectrogram)\n",
    "    freq_bins = tf.shape(aug_spec)[0]\n",
    "    time_steps = tf.shape(aug_spec)[1]\n",
    "    # Mascheramento Frequenza\n",
    "    f_param = tf.cast(tf.cast(freq_bins, tf.float32) * 0.2, tf.int32)\n",
    "    if f_param > 1:\n",
    "        f = tf.random.uniform(shape=(), minval=1, maxval=f_param, dtype=tf.int32)\n",
    "        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n",
    "        mask_freq_values = tf.concat([tf.ones((f0,)), tf.zeros((f,)), tf.ones((freq_bins - f0 - f,))], axis=0)\n",
    "        mask_freq = tf.reshape(tf.cast(mask_freq_values, aug_spec.dtype), (freq_bins, 1, 1))\n",
    "        aug_spec *= mask_freq\n",
    "    # Mascheramento Tempo\n",
    "    t_param = tf.cast(tf.cast(time_steps, tf.float32) * 0.2, tf.int32)\n",
    "    if t_param > 1:\n",
    "        t = tf.random.uniform(shape=(), minval=1, maxval=t_param, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n",
    "        mask_time_values = tf.concat([tf.ones((t0,)), tf.zeros((t,)), tf.ones((time_steps - t0 - t,))], axis=0)\n",
    "        mask_time = tf.reshape(tf.cast(mask_time_values, aug_spec.dtype), (1, time_steps, 1))\n",
    "        aug_spec *= mask_time\n",
    "    return aug_spec, label\n",
    "\n",
    "# Classe per orchestrare l'esperimento comparativo\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, class_names):\n",
    "        self.class_names = class_names\n",
    "        self.results = []\n",
    "\n",
    "    def run_experiments(self, model_factories, train_data, val_data, test_data, epochs, batch_size):\n",
    "        for model_name, model_factory in model_factories.items():\n",
    "            print(f\"\\n{'='*80}\\nARCHITETTURA IN TEST: '{model_name}'\\n{'='*80}\")\n",
    "            try:\n",
    "                model = model_factory()\n",
    "                # Usiamo solo Adam con un setup semplice e robusto\n",
    "                optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                \n",
    "                callbacks_list = [\n",
    "                    callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1),\n",
    "                    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1),\n",
    "                    callbacks.ModelCheckpoint(os.path.join(MODELS_PATH, f\"{model_name}_best.keras\"), \n",
    "                                              monitor='val_accuracy', save_best_only=True)\n",
    "                ]\n",
    "                \n",
    "                history = model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=callbacks_list, verbose=2)\n",
    "                \n",
    "                test_loss, test_acc = model.evaluate(test_data, verbose=0)\n",
    "                self.results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Test_Accuracy': test_acc,\n",
    "                    'Test_Loss': test_loss,\n",
    "                    'Best_Val_Accuracy': max(history.history['val_accuracy']),\n",
    "                    'Epochs_Run': len(history.history['val_accuracy']),\n",
    "                })\n",
    "            except Exception:\n",
    "                print(f\"❌ ERRORE durante il training di [{model_name}]:\")\n",
    "                traceback.print_exc()\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ESECUZIONE DEL CICLO DI TRAINING\n",
    "# -------------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# Assicuriamoci che i tipi di dato siano corretti\n",
    "y_train_cat = y_train_cat.astype('float32')\n",
    "y_val_cat = y_val_cat.astype('float32')\n",
    "y_test_cat = y_test_cat.astype('float32')\n",
    "\n",
    "# Pipeline di dati (solo SpecAugment, niente Mixup per un test più pulito)\n",
    "train_pipeline = (tf.data.Dataset.from_tensor_slices((X_train, y_train_cat)).cache().shuffle(len(X_train))\n",
    "                  .map(spec_augment_tf, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "val_pipeline = (tf.data.Dataset.from_tensor_slices((X_val, y_val_cat)).cache().batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "test_pipeline = (tf.data.Dataset.from_tensor_slices((X_test, y_test_cat)).cache().batch(BATCH_SIZE).prefetch(AUTOTUNE))\n",
    "\n",
    "# Factory dei modelli per il torneo\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train_cat.shape[1]\n",
    "model_factories = {\n",
    "    'SE_AudioCNN': lambda: ModelFactory.build_se_audio_cnn(input_shape, num_classes),\n",
    "    'ResSE_AudioCNN': lambda: ModelFactory.build_res_se_audio_cnn(input_shape, num_classes),\n",
    "    'ResNeXt_SE_AudioCNN': lambda: ModelFactory.build_resnext_se_audio_cnn(input_shape, num_classes),\n",
    "}\n",
    "\n",
    "# Esecuzione del torneo\n",
    "evaluator = ModelEvaluator(class_names=label_encoder.classes_)\n",
    "results_df = evaluator.run_experiments(\n",
    "    model_factories, train_pipeline, val_pipeline, test_pipeline, EPOCHS, BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Salvataggio e Report dei risultati del torneo\n",
    "if not results_df.empty:\n",
    "    results_df.to_csv(os.path.join(REPORTS_PATH, 'training_summary.csv'), index=False)\n",
    "    print(\"\\n🎉 CHAMPIONSHIP RUN COMPLETATO 🎉\")\n",
    "    print(\"\\nRisultati Finali:\")\n",
    "    print(results_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6a6906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 CHAMPIONSHIP RUN COMPLETATO 🎉\n",
      "\n",
      "Risultati Finali:\n",
      "| Model               |   Test_Accuracy |   Test_Loss |   Best_Val_Accuracy |   Epochs_Run |\n",
      "|:--------------------|----------------:|------------:|--------------------:|-------------:|\n",
      "| SE_AudioCNN         |          0.696  |    0.936001 |              0.7235 |           50 |\n",
      "| ResSE_AudioCNN      |          0.7805 |    0.926292 |              0.793  |           42 |\n",
      "| ResNeXt_SE_AudioCNN |          0.7795 |    0.99514  |              0.7675 |           46 |\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    results_df.to_csv(os.path.join(REPORTS_PATH, 'training_summary_CHAMPIONSHIP_RUN.csv'), index=False)\n",
    "    print(\"\\n🎉 CHAMPIONSHIP RUN COMPLETATO 🎉\")\n",
    "    print(\"\\nRisultati Finali:\")\n",
    "    print(results_df.to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
